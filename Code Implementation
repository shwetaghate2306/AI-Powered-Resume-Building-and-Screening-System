Step 1: Setting Up the Environment
Install the necessary libraries:

pip install pandas numpy nltk scikit-learn pdfminer.six spacy
pdfminer.six — Extracts text from PDF resumes
spaCy/NLTK — Processes natural language data
Scikit-Learn — Implements machine learning models

Step 2: Collecting and Preprocessing Resume Data
For this project, we need a dataset containing resumes and their corresponding job categories. A sample dataset might look like this:


We will extract text from these resumes using pdfminer.six.

from pdfminer.high_level import extract_text
import os

def extract_resume_text(pdf_path):
    text = extract_text(pdf_path)
    return text

# Example usage
resume_text = extract_resume_text("sample_resume.pdf")
print(resume_text[:500])  # Print first 500 characters
This function reads the text content from resumes, allowing us to process and analyze them.

Step 3: Cleaning and Preprocessing Resumes
We need to clean the extracted text before using it for ML modeling.

import re
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def clean_resume(text):
    text = re.sub(r'\n+', ' ', text)  # Remove newlines
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)  # Remove special characters
    text = text.lower()  # Convert to lowercase
    words = text.split()
    words = [word for word in words if word not in stop_words]  # Remove stopwords
    return ' '.join(words)

# Cleaned text
cleaned_resume = clean_resume(resume_text)
print(cleaned_resume[:500])

Step 4: Categorizing Resumes Using NLP
We will now classify resumes into job categories using TF-IDF (Term Frequency-Inverse Document Frequency) and Logistic Regression.

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load sample dataset
df = pd.read_csv("resumes.csv")  # Contains columns: "resume_text", "category"

# Convert text data into numerical features
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["resume_text"])

# Encode job categories
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y = encoder.fit_transform(df["category"])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
Here, we:

Convert resume text into numerical vectors using TF-IDF
Train a Logistic Regression model to classify resumes into job categories
Achieve high accuracy in categorizing candidates

Step 5: Ranking Candidates Based on Job Descriptions
Now, we compare resumes against a given job description to rank candidates based on relevance.

from sklearn.metrics.pairwise import cosine_similarity

def rank_resumes(job_description, resumes):
    job_vector = vectorizer.transform([job_description])
    resume_vectors = vectorizer.transform(resumes)
    scores = cosine_similarity(job_vector, resume_vectors).flatten()
    return scores

# Example job description
job_desc = "Looking for a Data Scientist with experience in Python, Machine Learning, and Deep Learning."

# Sample resumes
resume_texts = df["resume_text"][:10]
scores = rank_resumes(job_desc, resume_texts)

# Display ranking
df["match_score"] = scores
df_sorted = df.sort_values(by="match_score", ascending=False)
print(df_sorted[["category", "match_score"]])
This function calculates cosine similarity between job descriptions and resumes, ranking them based on relevance.

Step 6: Deploying the Resume Screening System
To make our system user-friendly, we can deploy it as a web application using Flask.

from flask import Flask, request, render_template

app = Flask(__name__)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    job_desc = request.form["job_description"]
    resume_text = request.form["resume_text"]
    score = rank_resumes(job_desc, [resume_text])[0]
    return f"Resume Match Score: {score:.2f}"

if __name__ == '__main__':
    app.run(debug=True)
This allows recruiters to input job descriptions and resumes via a web interface to get instant rankings.

Future Enhancements Ideas
Use Deep Learning (BERT/GPT) for better resume understanding
Extract additional features like skills and experience
Integrate LinkedIn profiles for candidate evaluation
Deploy as an API for HR software integration
Wrapping up
Today, we built an AI-powered Resume Screening System that:

Extracts text from resumes
Cleans and processes resume data
Classifies resumes into job categories
Ranks candidates based on job descriptions
Deploys as a Flask web app
